{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U4wYqxHL5XJQ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "import contractions\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "import gensim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import utils\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versions\n",
    "##### gensim : 1.22.4\n",
    "##### tensorflow: 2.11.0\n",
    "##### numpy: 1.22.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ga5BM5vd5wBE",
    "outputId": "e2ed35dd-baca-47a5-aaef-602907dff6f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jRE30QBD5Ynl",
    "outputId": "8fa718b0-8b73-4980-a503-e491e04786e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "#load the google news word2vec model from gensim \n",
    "import gensim.downloader as api\n",
    "\n",
    "google_news_w2v = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wF_KTIm5I3J9"
   },
   "source": [
    "## 1. Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M1-lGgIF5J6N"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('drive/MyDrive/hw3/data3.tsv', sep='\\t', on_bad_lines = 'skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FQXS8SWl5MvY"
   },
   "outputs": [],
   "source": [
    "df = df[['star_rating','review_body']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J8meMNFe5Mx2"
   },
   "outputs": [],
   "source": [
    "# A little bit cleaning before we split the classes\n",
    "\n",
    "df['star_rating'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XkVzXiPZ5M0H"
   },
   "outputs": [],
   "source": [
    "#dropping random rows with random date values\n",
    "\n",
    "df = df.drop(df[df.star_rating.isin(['2015-08-28', '2015-08-16', '2015-08-14', '2015-07-27', '2015-07-26', '2015-07-23',\n",
    "       '2015-07-22','2015-06-14', '2015-06-02', '2015-04-14',\n",
    "       '2015-04-09', '2015-04-08', '2015-04-03', '2015-04-02',\n",
    "       '2015-04-01', '2015-03-31', '2015-03-30', '2015-03-18',\n",
    "       '2015-02-28', '2015-02-10', '2014-12-30', '2014-12-03',\n",
    "       '2014-10-09'])].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4hegHPVq5M2L"
   },
   "outputs": [],
   "source": [
    "#dropping missing values\n",
    "\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x6qLRygK5M4Q"
   },
   "outputs": [],
   "source": [
    "#converting data type of star rating to int\n",
    "\n",
    "df['star_rating'] = df['star_rating'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B3x5Zl3u5M6e"
   },
   "outputs": [],
   "source": [
    "#Converting reviews to lower case\n",
    "\n",
    "df['review_body'] = df['review_body'].apply(str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "naA4-WaL5bko"
   },
   "outputs": [],
   "source": [
    "#Removing HTML lines from reviews\n",
    "\n",
    "df['review_body'] = df['review_body'].apply(lambda row:BeautifulSoup(row, 'html.parser').get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ntAwZcF5bnF"
   },
   "outputs": [],
   "source": [
    "#Removing URLs from reviews\n",
    "\n",
    "df['review_body'] = df['review_body'].apply(lambda row:re.sub(r'\\s*(https?://|www\\.)+\\S+(\\s+|$)', ' ', row, flags = re.UNICODE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HTIrsh4K5bqv"
   },
   "outputs": [],
   "source": [
    "#removing non-alphabetical characters\n",
    "\n",
    "df['review_body'] = df['review_body'].apply(lambda text:re.sub(r\"[^a-zA-Z' ]\", ' ', text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t5GDkJrP5btO"
   },
   "outputs": [],
   "source": [
    "#applying contractions\n",
    "\n",
    "df['review_body'] = df['review_body'].apply(lambda text: contractions.fix(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UioCwA-Q5bvc"
   },
   "outputs": [],
   "source": [
    "#creating a new column according to specified labels (Star Rating 1 and 2 = Class 1, 3 = Class 2, 4 and 5 = Class 3)\n",
    "\n",
    "def labeler(x):\n",
    "    if x == 1 or x == 2:\n",
    "        return 'Class 1'\n",
    "    elif (x == 3):\n",
    "        return 'Class 2'\n",
    "    elif x == 4 or x == 5:\n",
    "        return 'Class 3'\n",
    "    \n",
    "#applying the labeler function to 'star_rating' column \n",
    "df['class'] = df['star_rating'].apply(labeler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mYT1Wn5L5bxy"
   },
   "outputs": [],
   "source": [
    "# Grouping by class and taking 20000 samples from each class\n",
    "\n",
    "df = df.groupby('class').sample(n=20000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7iej9WgY5bz4"
   },
   "outputs": [],
   "source": [
    "df.to_csv('drive/MyDrive/hw3/df_colab.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L_FZGbQilLG7"
   },
   "source": [
    "Half of the dataset cleaning was performed outside colab in a jupyter notebook since google colab was not allowing me to upload .tsv file. The code for cleaning is given above and then it was stored as 'df_colab.csv' which contains the 60k reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Kd9xURxi8LhJ"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('drive/MyDrive/hw3/df_colab.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 468
    },
    "id": "_fo-6NIPBflg",
    "outputId": "6e35ea2a-d997-4c90-eded-a8c092aa37c5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-a50b9ea4-30e6-46a1-8c4d-9ff7691c30c6\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4132182</td>\n",
       "      <td>1</td>\n",
       "      <td>really really thin and small extension it does...</td>\n",
       "      <td>Class 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3704580</td>\n",
       "      <td>2</td>\n",
       "      <td>i ordered a reconditioned remington ms      ap...</td>\n",
       "      <td>Class 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2794197</td>\n",
       "      <td>2</td>\n",
       "      <td>the product is not as pictured   i was wanting...</td>\n",
       "      <td>Class 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3556189</td>\n",
       "      <td>2</td>\n",
       "      <td>the colour is much darker then i thought it wo...</td>\n",
       "      <td>Class 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4307159</td>\n",
       "      <td>1</td>\n",
       "      <td>this item could not be made any worse yet stil...</td>\n",
       "      <td>Class 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63502</th>\n",
       "      <td>3510151</td>\n",
       "      <td>4</td>\n",
       "      <td>i have now had this mirror for two years or so...</td>\n",
       "      <td>Class 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63503</th>\n",
       "      <td>4325318</td>\n",
       "      <td>4</td>\n",
       "      <td>it was delivered faster than expected  and abo...</td>\n",
       "      <td>Class 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63504</th>\n",
       "      <td>2800938</td>\n",
       "      <td>5</td>\n",
       "      <td>great product  i tried many other products and...</td>\n",
       "      <td>Class 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63505</th>\n",
       "      <td>2065657</td>\n",
       "      <td>5</td>\n",
       "      <td>great stuff  works great and both water and no...</td>\n",
       "      <td>Class 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63506</th>\n",
       "      <td>2783733</td>\n",
       "      <td>5</td>\n",
       "      <td>best moisture i have ever used</td>\n",
       "      <td>Class 3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63507 rows × 4 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a50b9ea4-30e6-46a1-8c4d-9ff7691c30c6')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-a50b9ea4-30e6-46a1-8c4d-9ff7691c30c6 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-a50b9ea4-30e6-46a1-8c4d-9ff7691c30c6');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "       Unnamed: 0  star_rating  \\\n",
       "0         4132182            1   \n",
       "1         3704580            2   \n",
       "2         2794197            2   \n",
       "3         3556189            2   \n",
       "4         4307159            1   \n",
       "...           ...          ...   \n",
       "63502     3510151            4   \n",
       "63503     4325318            4   \n",
       "63504     2800938            5   \n",
       "63505     2065657            5   \n",
       "63506     2783733            5   \n",
       "\n",
       "                                             review_body    class  \n",
       "0      really really thin and small extension it does...  Class 1  \n",
       "1      i ordered a reconditioned remington ms      ap...  Class 1  \n",
       "2      the product is not as pictured   i was wanting...  Class 1  \n",
       "3      the colour is much darker then i thought it wo...  Class 1  \n",
       "4      this item could not be made any worse yet stil...  Class 1  \n",
       "...                                                  ...      ...  \n",
       "63502  i have now had this mirror for two years or so...  Class 3  \n",
       "63503  it was delivered faster than expected  and abo...  Class 3  \n",
       "63504  great product  i tried many other products and...  Class 3  \n",
       "63505  great stuff  works great and both water and no...  Class 3  \n",
       "63506                    best moisture i have ever used   Class 3  \n",
       "\n",
       "[63507 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "24RbUVeHq_Bj"
   },
   "outputs": [],
   "source": [
    "df['class'].replace(['Class 1', 'Class 2', 'Class 3'],\n",
    "                        [1, 2, 3], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ND_2zfSF7H9p"
   },
   "outputs": [],
   "source": [
    "all_words = [row.split(' ') for row in df['review_body']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "9c7PFcBI7IAp"
   },
   "outputs": [],
   "source": [
    "all_words = [[item for item in sub_list if item != ''] for sub_list in all_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H0RCgHyx9CsO"
   },
   "source": [
    "## 2. Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "P4eLRim_7IDW"
   },
   "outputs": [],
   "source": [
    "word2vec_model = gensim.models.Word2Vec(all_words, size=300, window=11, min_count=10, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "QhSo3TNa2zMl"
   },
   "outputs": [],
   "source": [
    "word2vec_model.save('word2vec_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "xKyQQ0UA2dk4"
   },
   "outputs": [],
   "source": [
    "saved_word2vec_model = gensim.models.Word2Vec.load('word2vec_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SbFVh-q72lSO",
    "outputId": "eaa41fb2-13f4-41c7-e7eb-cd139d3a87f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity of the words using pre-trained model - excellent and outstanding: 0.6325795650482178\n",
      "Most similar word using pre-trained model: [('unavailable', 0.5172719955444336)]\n",
      "Most similar word using pre-trained model: [('orangey', 0.5602223873138428)]\n",
      "Most similar word using pre-trained model: [('highlighted', 0.5245702266693115)]\n",
      "Similarity of the words using pre-trained model - pretty and cute: 0.4033522307872772\n"
     ]
    }
   ],
   "source": [
    "#find similarity of the words using custom model\n",
    "\n",
    "#Example 1 - given\n",
    "\n",
    "print(f\"Similarity of the words using pre-trained model - excellent and outstanding: {saved_word2vec_model.wv.similarity('excellent', 'outstanding')}\")\n",
    "\n",
    "#Example 2 - given\n",
    "\n",
    "print(f\"Most similar word using pre-trained model: {saved_word2vec_model.wv.most_similar(positive = ['king','woman'], negative = ['man'], topn=1)}\")\n",
    "\n",
    "#Example 3 - my own\n",
    "\n",
    "print(f\"Most similar word using pre-trained model: {saved_word2vec_model.wv.most_similar(positive = ['lipstick','red'], negative = ['lips'], topn=1)}\")\n",
    "\n",
    "#Example 4 - my own\n",
    "\n",
    "print(f\"Most similar word using pre-trained model: {saved_word2vec_model.most_similar(positive=['hair','brown'], negative = ['color'], topn=1)}\")\n",
    "\n",
    "#Example 5 - my own\n",
    "\n",
    "print(f\"Similarity of the words using pre-trained model - pretty and cute: {saved_word2vec_model.similarity('pretty', 'cute')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zSWFgyHN7IF9",
    "outputId": "f1a1cac9-3b49-4628-8596-e4490b726a55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity of the words using pre-trained model - excellent and outstanding: 0.5567485690116882\n",
      "Most similar word using pre-trained model: [('queen', 0.7118192911148071)]\n",
      "Most similar word using pre-trained model: [('yellow', 0.5638219118118286)]\n",
      "Most similar word using pre-trained model: [('curly_hair', 0.6184735298156738)]\n",
      "Similarity of the words using pre-trained model - pretty and cute: 0.3201156556606293\n"
     ]
    }
   ],
   "source": [
    "#find similarity of the words using pre-trained model\n",
    "\n",
    "#Example 1 - given\n",
    "\n",
    "print(f\"Similarity of the words using pre-trained model - excellent and outstanding: {google_news_w2v.similarity('excellent', 'outstanding')}\")\n",
    "\n",
    "#Example 2 - given \n",
    "\n",
    "print(f\"Most similar word using pre-trained model: {google_news_w2v.most_similar(positive = ['king','woman'], negative = ['man'], topn=1)}\")\n",
    "\n",
    "#Example 3 - my own\n",
    "\n",
    "print(f\"Most similar word using pre-trained model: {google_news_w2v.most_similar(positive=['lipstick','red'], negative = ['lips'], topn=1)}\")\n",
    "\n",
    "#Example 4 - my own\n",
    "\n",
    "print(f\"Most similar word using pre-trained model: {google_news_w2v.most_similar(positive=['hair','brown'], negative = ['color'], topn=1)}\")\n",
    "\n",
    "#Example 5 - my own\n",
    "\n",
    "print(f\"Similarity of the words using pre-trained model - pretty and cute: {google_news_w2v.similarity('pretty', 'cute')}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BKwoV5_D4I6z"
   },
   "source": [
    "*What do you conclude from comparing vectors generated by yourself and the pretrained model? Which of the Word2Vec models seems to encode semantic similarities between words better?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q4bdSSRu4Qcm"
   },
   "source": [
    "From the above results, the word vectors generated by my word2vec model performs better  than the vectors generated by google_news dataset in example 1 which is between the words  'excellent ' and 'outstanding' (semantic similarity my vectors: 0.6325795650482178 and semantic similarity google's vectors:  0.556748628616333).\n",
    "\n",
    "For example 2 which is king + woman - man, the Google Word2Vec model performs much better than my model (google's vectors: [('queen', 0.7118193507194519)] , my vectors: [('unavailable', 0.5172719955444336)]). This is because king and queen are not available in my vocabulary. \n",
    "\n",
    "For one of my own examples (example 3) which is 'lipstick'+'red'-'lips,' my model performs better as it gives out the result 'orangey,' which is much closer to the words than the word predicted by google, which was 'yellow.' This might be the case because my model was trained on vectors generated on a 'Beauty' reviews dataset which might lead it to perform better when words from that dataset are used, even when the google model was trained on a vast corpus.\n",
    "\n",
    "In conclusion, my model seems to perform better compared to google's."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VZ5uUn9K7bp-"
   },
   "source": [
    "## 3. Simple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "5PxSRueC7IIL"
   },
   "outputs": [],
   "source": [
    "def average_of_word_vectors(review, w2v_model):\n",
    "    review_words = review.split(' ')\n",
    "    \n",
    "    review_words_vectors = []\n",
    "    for word in review_words:\n",
    "        try:\n",
    "            review_words_vectors.append(w2v_model[word])\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "    if len(review_words_vectors) != 0:\n",
    "        return np.mean(review_words_vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "Q_5dypgd7IKq"
   },
   "outputs": [],
   "source": [
    "df['average_features'] = df['review_body'].apply(lambda review: average_of_word_vectors(review, google_news_w2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "Nu_XiTxO7IPg"
   },
   "outputs": [],
   "source": [
    "X = df['average_features'] #data\n",
    "y = df['class']   #class\n",
    "\n",
    "\n",
    "# Split the dataset into 80% train set and 20% test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train.to_list()\n",
    "X_test  = X_test.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NDmEFWsV7ISF",
    "outputId": "02851048-8267-4cbc-c309-7cb05c9ba9a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Perceptron----------\n",
      "\n",
      "Accuracy score of perceptron model: 0.5517241379310345\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "# training SVM model on the average vectors\n",
    "perceptron_clf = Perceptron(n_jobs=-1, random_state=123)\n",
    "perceptron_clf.fit(X_train, y_train)\n",
    "\n",
    "# predicting the labels on test split\n",
    "y_pred_test = perceptron_clf.predict(X_test)\n",
    "\n",
    "print(\"----------Perceptron----------\\n\")\n",
    "print(f\"Accuracy score of Perceptron model: {accuracy_score(y_test, y_pred_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l_h7sbes7IUc",
    "outputId": "8535158e-dd90-4b3d-947b-0b1a63398260"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------SVM----------\n",
      "\n",
      "Accuracy score of SVM model: 0.6557235081089592\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "# training SVM model on the average vectors\n",
    "svm_clf = svm.LinearSVC(random_state=27)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "# predicting the labels on test split\n",
    "y_pred_test = svm_clf.predict(X_test)\n",
    "\n",
    "print(\"----------SVM----------\\n\")\n",
    "print(f\"Accuracy score of SVM model: {accuracy_score(y_test, y_pred_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xlw4Nug59Ie1"
   },
   "source": [
    "What do you conclude from comparing performances for the models trained using the two different feature types (TF-IDF and your trained Word2Vec features)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XaJLHwZ1AvG3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Google-W2V</td>\n",
       "      <td>Perceptron</td>\n",
       "      <td>0.5517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>Perceptron</td>\n",
       "      <td>0.6900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Google-W2V</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.6557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.7134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Features       Model Accuracy\n",
       "0  Google-W2V  Perceptron   0.5517\n",
       "1      TF-IDF  Perceptron   0.6900\n",
       "2  Google-W2V         SVM   0.6557\n",
       "3      TF-IDF         SVM   0.7134"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies = {\"Features\": [\"Google-W2V\", \"TF-IDF\", \"Google-W2V\", \"TF-IDF\"],\n",
    "          \"Model\": [\"Perceptron\", \"Perceptron\", \"SVM\", \"SVM\"], \n",
    "          \"Accuracy\": [\"0.5517\", \"0.6900\", \"0.6557\", \"0.7134\"]}\n",
    "\n",
    "df_report = pd.DataFrame(accuracies)\n",
    "df_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06tzdK_09STi"
   },
   "source": [
    "By comparing the accuracies here, we can conclude that TF-IDF features perform much better than Word2Vec features for our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7eTvpZ3qF4Qc"
   },
   "source": [
    "## 4. Feed-Forward Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gyzQh07iC2uK"
   },
   "source": [
    "### 4A: Average Word2Vec Vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "Q0-YkcHiCuKf"
   },
   "outputs": [],
   "source": [
    "X = df['average_features'] #data\n",
    "y = df['class']   #class\n",
    "\n",
    "\n",
    "# Split the dataset into 80% train set and 20% test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train.to_list()\n",
    "X_test  = X_test.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "un34kS9mptM7"
   },
   "outputs": [],
   "source": [
    " X_train_array_fnn = np.array(X_train)\n",
    " X_test_array_fnn = np.array(X_test)\n",
    " y_train_array_fnn = np.array(y_train)\n",
    " y_test_array_fnn = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "HStnlkfoqJti"
   },
   "outputs": [],
   "source": [
    "y_train_array_int_fnn = utils.to_categorical(y_train_array_fnn - 1 , num_classes=3)\n",
    "y_test_array_int_fnn = utils.to_categorical(y_test_array_fnn - 1 , num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0WRq94Zt7IbZ",
    "outputId": "14b8e8b0-0442-4c1b-ad02-4b6e9b53cd56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_11 (Dense)            (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 3)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,143\n",
      "Trainable params: 31,143\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_fnn = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation='relu', input_dim=300),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "model_fnn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "T-8AMYXa7Id3"
   },
   "outputs": [],
   "source": [
    "model_fnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2jk4j_VV7Iif",
    "outputId": "d41b00b1-ef9a-4fd9-ed71-d427359e45f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_11 (Dense)            (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 3)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,143\n",
      "Trainable params: 31,143\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_fnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e7Klgw_Y7Ik1",
    "outputId": "3b22a8ea-c6ea-4119-98ef-d3cfa8f194fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "1588/1588 [==============================] - 7s 3ms/step - loss: 0.8217 - accuracy: 0.6263 - val_loss: 0.7795 - val_accuracy: 0.6565\n",
      "Epoch 2/8\n",
      "1588/1588 [==============================] - 5s 3ms/step - loss: 0.7588 - accuracy: 0.6626 - val_loss: 0.7589 - val_accuracy: 0.6621\n",
      "Epoch 3/8\n",
      "1588/1588 [==============================] - 5s 3ms/step - loss: 0.7406 - accuracy: 0.6708 - val_loss: 0.7549 - val_accuracy: 0.6660\n",
      "Epoch 4/8\n",
      "1588/1588 [==============================] - 5s 3ms/step - loss: 0.7285 - accuracy: 0.6776 - val_loss: 0.7530 - val_accuracy: 0.6653\n",
      "Epoch 5/8\n",
      "1588/1588 [==============================] - 5s 3ms/step - loss: 0.7179 - accuracy: 0.6808 - val_loss: 0.7564 - val_accuracy: 0.6656\n",
      "Epoch 6/8\n",
      "1588/1588 [==============================] - 5s 3ms/step - loss: 0.7078 - accuracy: 0.6864 - val_loss: 0.7470 - val_accuracy: 0.6718\n",
      "Epoch 7/8\n",
      "1588/1588 [==============================] - 5s 3ms/step - loss: 0.7005 - accuracy: 0.6905 - val_loss: 0.7447 - val_accuracy: 0.6695\n",
      "Epoch 8/8\n",
      "1588/1588 [==============================] - 5s 3ms/step - loss: 0.6923 - accuracy: 0.6949 - val_loss: 0.7417 - val_accuracy: 0.6719\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ef84cf9b3d0>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fnn.fit(X_train_array_fnn, y_train_array_int_fnn, epochs=8, verbose=1, validation_split=0.1,\n",
    "          validation_data=(X_test_array_fnn, y_test_array_int_fnn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rAwcas5LZTQY"
   },
   "source": [
    "FNN Accuracy (Average vectors): 67.19% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JgC0MqRktMGO"
   },
   "source": [
    "### 4B: Concatenating the first 10 Word2Vec Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "uIFBogeKQtxd"
   },
   "outputs": [],
   "source": [
    "def length_10(review, word2vec_model):\n",
    "    tokens = review.split()\n",
    "    vectors = [word2vec_model.wv[t] for t in tokens if t in word2vec_model.wv.vocab]\n",
    "    padded_vectors = vectors[:10] + [np.zeros(300)] * max(0, 10 - len(vectors))\n",
    "\n",
    "    return np.concatenate(padded_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "L-JxwwxFPI7s"
   },
   "outputs": [],
   "source": [
    "X = [length_10(review,word2vec_model) for review in df['review_body']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "Fpji-cbcR32G"
   },
   "outputs": [],
   "source": [
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "oOXV-uY27I1R"
   },
   "outputs": [],
   "source": [
    "# Split the dataset into 80% train set and 20% test set\n",
    "X_train_10, X_test_10, y_train_10, y_test_10 = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "is35xt8B7I3g"
   },
   "outputs": [],
   "source": [
    "X_train_array_fnn_10 = np.array(X_train_10)\n",
    "X_test_array_fnn_10  = np.array(X_test_10)\n",
    "y_train_array_fnn_10  = np.array(y_train_10)\n",
    "y_test_array_fnn_10  = np.array(y_test_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "Dez01tkskKZp"
   },
   "outputs": [],
   "source": [
    "y_train_array_int_fnn_10 = utils.to_categorical(y_train_array_fnn_10 - 1 , num_classes=3)\n",
    "y_test_array_int_fnn_10 = utils.to_categorical(y_test_array_fnn_10 - 1 , num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Z0xwkPYSHQv",
    "outputId": "e6c72d49-b432-4cb5-e714-dd30f60e9216"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 100)               300100    \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 3)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 301,143\n",
      "Trainable params: 301,143\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_fnn_10 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation='relu', input_dim=3000),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "model_fnn_10.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "pOfOREFkSS8V"
   },
   "outputs": [],
   "source": [
    "model_fnn_10.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KSzHDl357I5p",
    "outputId": "a121f336-c4eb-43b1-c062-db29cfe64e3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "1588/1588 [==============================] - 7s 4ms/step - loss: 0.8776 - accuracy: 0.5820 - val_loss: 0.8623 - val_accuracy: 0.5946\n",
      "Epoch 2/8\n",
      "1588/1588 [==============================] - 6s 3ms/step - loss: 0.7944 - accuracy: 0.6337 - val_loss: 0.8480 - val_accuracy: 0.6020\n",
      "Epoch 3/8\n",
      "1588/1588 [==============================] - 6s 4ms/step - loss: 0.7339 - accuracy: 0.6698 - val_loss: 0.8463 - val_accuracy: 0.6171\n",
      "Epoch 4/8\n",
      "1588/1588 [==============================] - 6s 3ms/step - loss: 0.6522 - accuracy: 0.7152 - val_loss: 0.8623 - val_accuracy: 0.6059\n",
      "Epoch 5/8\n",
      "1588/1588 [==============================] - 6s 3ms/step - loss: 0.5482 - accuracy: 0.7688 - val_loss: 0.9364 - val_accuracy: 0.6116\n",
      "Epoch 6/8\n",
      "1588/1588 [==============================] - 6s 4ms/step - loss: 0.4394 - accuracy: 0.8219 - val_loss: 1.1245 - val_accuracy: 0.5947\n",
      "Epoch 7/8\n",
      "1588/1588 [==============================] - 6s 4ms/step - loss: 0.3429 - accuracy: 0.8646 - val_loss: 1.2712 - val_accuracy: 0.6002\n",
      "Epoch 8/8\n",
      "1588/1588 [==============================] - 6s 3ms/step - loss: 0.2672 - accuracy: 0.8963 - val_loss: 1.4133 - val_accuracy: 0.5987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ef84d2787f0>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fnn_10.fit(X_train_array_fnn_10, y_train_array_int_fnn_10, epochs=8, verbose=1, validation_split=0.1,\n",
    "          validation_data=(X_test_array_fnn_10, y_test_array_int_fnn_10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LRb3w-ZhY-ip"
   },
   "source": [
    "FNN Accuracy (Concatenating first 10 words): 57.72% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NACNQ9tQHdFc"
   },
   "source": [
    "What do you conclude by comparing accuracy values you obtain with\n",
    "those obtained in the “’Simple Models” section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Km9HsiFHf3R"
   },
   "source": [
    "The accuracy results of the feedforward neural network models with different input features show that the model with the input feature as the average of all word vectors outperforms or performs similarly to the perceptron and SVM models. However, the feedforward neural network model with the input feature as the concatenation of the first ten word vectors performs worse than the SVM and slightly better than Perceptron models. This indicates that using the average of all word vectors as the input feature is a better choice than concatenating the first ten word vectors. Additionally, it can be concluded that the feedforward neural network model is more robust and slightly more accurate when the average of word vectors is used as the input feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jDky0L-CFqDr"
   },
   "source": [
    "## 5. Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3qbIbtYdWnhA"
   },
   "source": [
    "### 5A: Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "OcWOhcPb8IkM"
   },
   "outputs": [],
   "source": [
    "def length_20(review, word2vec_model):\n",
    "  review = review.split()\n",
    "  vector = [word2vec_model.wv.vocab[r].index for r in review if r in word2vec_model.wv.vocab]\n",
    "\n",
    "  if len(vector) > 20:\n",
    "    vector = vector[:20]\n",
    "  elif len(vector) < 20:\n",
    "    vector.extend([0] * (20 - len(vector)))\n",
    "\n",
    "  return np.array(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "a4qjRupbeNiU"
   },
   "outputs": [],
   "source": [
    "X_rnn = [length_20(review,google_news_w2v) for review in df['review_body']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "deOYtYCAb69k"
   },
   "outputs": [],
   "source": [
    "y_rnn = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "0mzsTVWf5-U5"
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "HSNsg81Ub_zA"
   },
   "outputs": [],
   "source": [
    "# Split the dataset into 80% train set and 20% test set\n",
    "X_rnn_train, X_rnn_test, y_rnn_train, y_rnn_test = train_test_split(X_rnn , y_rnn, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "T1xXoE1eb_15"
   },
   "outputs": [],
   "source": [
    " X_rnn_train_array = np.array(X_rnn_train)\n",
    " X_rnn_test_array  = np.array(X_rnn_test)\n",
    " y_rnn_train_array  = np.array(y_rnn_train)\n",
    " y_rnn_test_array  = np.array(y_rnn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "TjpvCc_1b_4Z"
   },
   "outputs": [],
   "source": [
    "y_train_array_int_rnn = utils.to_categorical(y_rnn_train_array - 1 , num_classes=3)\n",
    "y_test_array_int_rnn = utils.to_categorical(y_rnn_test_array - 1 , num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "HOdgpjlfZ3oo"
   },
   "outputs": [],
   "source": [
    "max_review_length= 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OAZi81dSb_7D",
    "outputId": "7a3eab53-032b-453c-d822-38947ed4b10b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 20, 300)           900000000 \n",
      "                                                                 \n",
      " simple_rnn_2 (SimpleRNN)    (None, 20)                6420      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 900,006,483\n",
      "Trainable params: 6,483\n",
      "Non-trainable params: 900,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_srnn = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=len(google_news_w2v.vocab), output_dim=300, weights=[google_news_w2v.wv.vectors], input_length=max_review_length, trainable=False),\n",
    "    tf.keras.layers.SimpleRNN(20), #SimpleRNN layer\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model_srnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "3oqxgNR_ETYz"
   },
   "outputs": [],
   "source": [
    "model_srnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yohf4IGQGjUE",
    "outputId": "6267d87b-e089-40c7-99a2-33a06d96e082"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "1588/1588 [==============================] - 27s 14ms/step - loss: 0.9370 - accuracy: 0.5346 - val_loss: 0.9306 - val_accuracy: 0.5546\n",
      "Epoch 2/8\n",
      "1588/1588 [==============================] - 21s 14ms/step - loss: 0.8733 - accuracy: 0.5904 - val_loss: 0.8818 - val_accuracy: 0.5900\n",
      "Epoch 3/8\n",
      "1588/1588 [==============================] - 22s 14ms/step - loss: 0.8438 - accuracy: 0.6146 - val_loss: 0.8685 - val_accuracy: 0.6038\n",
      "Epoch 4/8\n",
      "1588/1588 [==============================] - 21s 14ms/step - loss: 0.8317 - accuracy: 0.6222 - val_loss: 0.8606 - val_accuracy: 0.6069\n",
      "Epoch 5/8\n",
      "1588/1588 [==============================] - 22s 14ms/step - loss: 0.8213 - accuracy: 0.6285 - val_loss: 0.8562 - val_accuracy: 0.6082\n",
      "Epoch 6/8\n",
      "1588/1588 [==============================] - 21s 13ms/step - loss: 0.8162 - accuracy: 0.6319 - val_loss: 0.8580 - val_accuracy: 0.6027\n",
      "Epoch 7/8\n",
      "1588/1588 [==============================] - 21s 13ms/step - loss: 0.8066 - accuracy: 0.6366 - val_loss: 0.8637 - val_accuracy: 0.6115\n",
      "Epoch 8/8\n",
      "1588/1588 [==============================] - 22s 14ms/step - loss: 0.8024 - accuracy: 0.6412 - val_loss: 0.8592 - val_accuracy: 0.6081\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efadc179eb0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_srnn.fit(X_rnn_train_array, y_train_array_int_rnn, epochs=8, verbose=1, validation_split=0.1,\n",
    "          validation_data=(X_rnn_test_array, y_test_array_int_rnn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xixP_RaGFHtv"
   },
   "source": [
    "Simple RNN Accuracy (Concatenating first 10 words): 60.81%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-TRvNVljFBPt"
   },
   "source": [
    "### 5B: Gated Recurrent Unit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vTKz2sI3FDql",
    "outputId": "9a89c457-a937-4737-a56c-cb15ccdaf0f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 20, 300)           900000000 \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 20)                19320     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 900,019,383\n",
      "Trainable params: 19,383\n",
      "Non-trainable params: 900,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_grnn = tf.keras.Sequential([    \n",
    "    tf.keras.layers.Embedding(input_dim=len(google_news_w2v.vocab), output_dim=300, weights=[google_news_w2v.wv.vectors], input_length=max_review_length, trainable=False),\n",
    "    tf.keras.layers.GRU(20), #GRU layer\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model_grnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "sIvYv5XHFRQo"
   },
   "outputs": [],
   "source": [
    "model_grnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QuLlm_tcFRTG",
    "outputId": "2365c3f8-ddc2-4011-e660-f4733e550195"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "1588/1588 [==============================] - 12s 5ms/step - loss: 0.8777 - accuracy: 0.5728 - val_loss: 0.8191 - val_accuracy: 0.6265\n",
      "Epoch 2/8\n",
      "1588/1588 [==============================] - 8s 5ms/step - loss: 0.7639 - accuracy: 0.6551 - val_loss: 0.7780 - val_accuracy: 0.6479\n",
      "Epoch 3/8\n",
      "1588/1588 [==============================] - 7s 5ms/step - loss: 0.7360 - accuracy: 0.6698 - val_loss: 0.7633 - val_accuracy: 0.6551\n",
      "Epoch 4/8\n",
      "1588/1588 [==============================] - 7s 5ms/step - loss: 0.7172 - accuracy: 0.6809 - val_loss: 0.7601 - val_accuracy: 0.6560\n",
      "Epoch 5/8\n",
      "1588/1588 [==============================] - 7s 5ms/step - loss: 0.7013 - accuracy: 0.6878 - val_loss: 0.7402 - val_accuracy: 0.6653\n",
      "Epoch 6/8\n",
      "1588/1588 [==============================] - 7s 5ms/step - loss: 0.6862 - accuracy: 0.6966 - val_loss: 0.7362 - val_accuracy: 0.6701\n",
      "Epoch 7/8\n",
      "1588/1588 [==============================] - 8s 5ms/step - loss: 0.6760 - accuracy: 0.7020 - val_loss: 0.7380 - val_accuracy: 0.6682\n",
      "Epoch 8/8\n",
      "1588/1588 [==============================] - 8s 5ms/step - loss: 0.6661 - accuracy: 0.7063 - val_loss: 0.7360 - val_accuracy: 0.6730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efab635d940>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_grnn.fit(X_rnn_train_array, y_train_array_int_rnn, epochs=8, verbose=1, validation_split=0.1,\n",
    "          validation_data=(X_rnn_test_array, y_test_array_int_rnn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F_D1ucwmFIjX"
   },
   "source": [
    "GRU RNN Accuracy: 67.30%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5fu29cQFYdf"
   },
   "source": [
    "### 5C: LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RoQpcqv7FRVX",
    "outputId": "ec1a928d-9ce8-4759-edd5-4d629b89a970"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 20, 300)           900000000 \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 20)                25680     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 3)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 900,025,743\n",
      "Trainable params: 25,743\n",
      "Non-trainable params: 900,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_lrnn = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=len(google_news_w2v.vocab), output_dim=300, weights=[google_news_w2v.wv.vectors], input_length=max_review_length, trainable=False),\n",
    "    tf.keras.layers.LSTM(20),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model_lrnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "BfR-8unNFRXi"
   },
   "outputs": [],
   "source": [
    "model_lrnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2JU229ckFRZ0",
    "outputId": "0d11b0db-adff-46e5-bbec-9a0a638f7be5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "1588/1588 [==============================] - 11s 5ms/step - loss: 0.8606 - accuracy: 0.5969 - val_loss: 0.8235 - val_accuracy: 0.6258\n",
      "Epoch 2/8\n",
      "1588/1588 [==============================] - 8s 5ms/step - loss: 0.7769 - accuracy: 0.6497 - val_loss: 0.7889 - val_accuracy: 0.6401\n",
      "Epoch 3/8\n",
      "1588/1588 [==============================] - 8s 5ms/step - loss: 0.7452 - accuracy: 0.6656 - val_loss: 0.7675 - val_accuracy: 0.6534\n",
      "Epoch 4/8\n",
      "1588/1588 [==============================] - 8s 5ms/step - loss: 0.7236 - accuracy: 0.6764 - val_loss: 0.7852 - val_accuracy: 0.6480\n",
      "Epoch 5/8\n",
      "1588/1588 [==============================] - 8s 5ms/step - loss: 0.7059 - accuracy: 0.6825 - val_loss: 0.7595 - val_accuracy: 0.6581\n",
      "Epoch 6/8\n",
      "1588/1588 [==============================] - 8s 5ms/step - loss: 0.6918 - accuracy: 0.6926 - val_loss: 0.7585 - val_accuracy: 0.6551\n",
      "Epoch 7/8\n",
      "1588/1588 [==============================] - 8s 5ms/step - loss: 0.6774 - accuracy: 0.6984 - val_loss: 0.7560 - val_accuracy: 0.6628\n",
      "Epoch 8/8\n",
      "1588/1588 [==============================] - 8s 5ms/step - loss: 0.6655 - accuracy: 0.7048 - val_loss: 0.7515 - val_accuracy: 0.6623\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efa646866a0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lrnn.fit(X_rnn_train_array, y_train_array_int_rnn, epochs=8, verbose=1, validation_split=0.1,\n",
    "          validation_data=(X_rnn_test_array, y_test_array_int_rnn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DzbDqElnF2ak"
   },
   "source": [
    "LSTM RNN Accuracy: 66.23% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aXNaAO-Jf4MC"
   },
   "source": [
    "What do you conclude by comparing accuracy values you obtain by GRU,\n",
    "LSTM, and simple RNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jONA_PL2f4S7"
   },
   "source": [
    "Based on the accuracy results obtained for the SimpleRNN, GRU, and LSTM models, it can be inferred that the GRU model outperforms both the SimpleRNN and LSTM models. The superiority of the GRU model is attributed to its gated units, which enable it to retain long-term dependencies among words and thus improve prediction accuracy. In contrast, the RNN model lacks long-term memory and can only facilitate basic sequence prediction based on its short-term memory."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
